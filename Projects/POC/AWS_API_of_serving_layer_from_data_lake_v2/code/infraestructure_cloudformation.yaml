AWSTemplateFormatVersion: "2010-09-09"
Description: "Automaticed creation of all infraestructure to support POC case 1."

Parameters:
  DatalakeDBInGlue:
    Type: String
    MinLength: "4"
    Default: "db_poc_case_fifth"
    Description: Name of DB in AWS Glue database
  
  DataLakeInS3Name:
    Type: String
    MinLength: "4"
    Default: "s3-datalake-poc-case-5"
    Description: "Name of bucket will store the data lake tables."



Resources:
  ######
  ### Resource to generate database and data processing system
  ######

  ## Role will be used in IaC
  AWSGlueJobRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:  "*"
                Resource: "*"
      Path: "/" 

  # Resource to store data generated from Athena
  DataLakeInS3:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref DataLakeInS3Name
      PublicAccessBlockConfiguration:
        BlockPublicAcls: False
        BlockPublicPolicy: False
        IgnorePublicAcls: False
        RestrictPublicBuckets: False
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerPreferred

  ## Resource to prepare database (AWS GLUE)
  POCCase5Database:
    Type: "AWS::Glue::Database"
    Properties:
      DatabaseInput:
        Description: "Database to store all table in POC case 5"
        Name: !Ref DatalakeDBInGlue
        LocationUri: "s3://s3-storage-layer-poc-5/glue/"
      CatalogId: !Ref AWS::AccountId ## reference the same AWS account

  ## moving file s3-to-s3 using AWS Glue job
  S3ToIcebergGlueJob:
    Type: "AWS::Glue::Job"
    Properties:
      Role: !Ref AWSGlueJobRole
      Name: "CSVToIcebergTransformPOC5"
      GlueVersion: "3.0"
      WorkerType: "G.2X"
      NumberOfWorkers: 2
      Command : 
        Name: "glueetl"
        ScriptLocation: "s3://s3-storage-layer-poc-5/script/transform_to_iceberg_glue_job.py"
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--datalake-formats": "iceberg"
        "--conf": "spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://<BUCKET_NAME>/data/ticketdata_iceberg --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileI"
        "--bucket_origin": "s3-storage-layer-poc-5/raw_csv_files"
        "--glue_schema_db": "db_poc_case_fifth"
      MaxRetries: 0
      Description: "transform files from CSV format to iceberg format script"

  AccessControlScript:
    Type: "AWS::Glue::Job"
    Properties:
      Role: !Ref AWSGlueJobRole
      Name: "GenerateFakedExtendedAccessControlModel"
      GlueVersion: "3.0"
      WorkerType: "G.2X"
      NumberOfWorkers: 2
      Command : 
        Name: "glueetl"
        ScriptLocation: "s3://s3-storage-layer-poc-5/script/generate_extended_access_control.py"
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--datalake-formats": "iceberg"
        "--conf": "spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://<BUCKET_NAME>/data/ticketdata_iceberg --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileI"
      MaxRetries: 0
      Description: "generate a extended access control model for POC 5"

