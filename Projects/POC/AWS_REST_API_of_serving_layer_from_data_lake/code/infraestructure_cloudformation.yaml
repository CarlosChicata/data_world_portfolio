AWSTemplateFormatVersion: "2010-09-09"
Description: "Automaticed creation of all infraestructure to support POC case 1."

Parameters:
  DatalakeDBInGlue:
    Type: String
    MinLength: "4"
    Default: "db-poc-case-1"
    Description: Name of DB in AWS Glue database

  DatalakeS3Name:
    Type: String
    MinLength: "4"
    Default: "s3-datalake-poc-case-1"
    Description: "Name of bucket will get all parquet files (tables)."

  AccessControlDBS3Name:
    Type: String
    MinLength: "4"
    Default: "db-controlaccess-poc-case-1"
    Description: "DB contain all access control to authorizer process in API."
  
  ResultedQueryStoreS3:
    Type: String
    MinLength: "4"
    Default: "s3-stored-queries-poc-case-1"
    Description: "Name of bucket will store teh result of queries from athena"

  DataUserConsumerAPIName:
    Type: String
    MinLength: "4"
    Default: "third-consumer-data-api"
    Description: "Name of API to deliver data"


Resources:
  ######
  ### Resource to generate database and data processing system
  ######

  ## Role will be used in IaC
  AWSGlueJobRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:  "*"
                Resource: "*"
      Path: "/" 

  ## Resource to get tables (AWS S3)
  DatalakeS3:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref DatalakeS3Name
      AccessControl: "PublicReadWrite"

  # Resource to store data generated from Athena
  ResultQueriesAthenaS3:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref ResultedQueryStoreS3
      AccessControl: "PublicReadWrite"

  ## Resource to prepare database (AWS GLUE)
  POCCase1Database:
    Type: "AWS::Glue::Database"
    Properties:
      DatabaseInput:
        Description: "Database to store all table in POC case 1"
        Name: !Ref DatalakeDBInGlue
      CatalogId: !Ref AWS::AccountId ## reference the same AWS account

  ## moving file s3-to-s3 using AWS Glue job
  S3ToS3GlueJob:
    Type: "AWS::Glue::Job"
    Properties:
      Role: !Ref AWSGlueJobRole
      Name: "S3ToS3Moving"
      Command : 
        Name: "pythonshell"
        PythonVersion: "3.9"
        ScriptLocation: "s3://script-poc-case-1/load_tables.py"
      DefaultArguments:
        "--bucket-origin": "poc-case-1-table-demo"
        "--bucket-destiny" : !Ref DatalakeS3Name
      MaxRetries: 0
      Description: "Moving files from S3 to S3 script"

  ## preparing athena workspace
  AthenaWorkSpace:
    Type: "AWS::Athena::WorkGroup"
    Properties:
      Description: "Resulted data storage from queries of AWS Athena."
      Name: "resulted-queries-athena-poc-case-1"
      WorkGroupConfiguration:
        ResultConfiguration: 
          OutputLocation:  !Join
            - "/"
            - - "s3:/"
              - !Ref ResultedQueryStoreS3

  ## get metadata of tables
  ParserMetadataTableGlueCrawler:
    Type: "AWS::Glue::Crawler"
    Properties:
      Name: "poc-case-1-crawler"
      Role: !Ref AWSGlueJobRole
      DatabaseName: !Ref POCCase1Database
      Targets:
        S3Targets: # manual adding data store
          - Path : "s3://s3-datalake-poc-case-1/city-table/"
          - Path : "s3://s3-datalake-poc-case-1/client-table/"
          - Path : "s3://s3-datalake-poc-case-1/country-table/"
          - Path : "s3://s3-datalake-poc-case-1/order-table/"
          - Path : "s3://s3-datalake-poc-case-1/product-size-table/"
          - Path : "s3://s3-datalake-poc-case-1/route-table/"
          - Path : "s3://s3-datalake-poc-case-1/service-table/"
          - Path : "s3://s3-datalake-poc-case-1/trackcode-table/"
  
  ######
  ### Resource to generate access control table in API
  ######

  AccessControlDBS3:
    Type: "AWS::Glue::Database"
    Properties:
      DatabaseInput:
        Description: "Database to store access control in POC case 1"
        Name: !Ref AccessControlDBS3Name
      CatalogId: !Ref AWS::AccountId ## reference the same AWS account

  ParserMetadataAccessControlGlueCrawler:
    Type: "AWS::Glue::Crawler"
    Properties:
      Name: "poc-case-1-crawler-access-control-data"
      Role: !Ref AWSGlueJobRole
      DatabaseName: !Ref AccessControlDBS3
      Targets:
        S3Targets: # manual adding data store
          - Path : "s3://s3-datalake-poc-case-1/access-control-table/"

  ######
  ### Resource to generate API
  ######

  AuthLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:  "*"
                Resource: "*"
      Path: "/" 

  DataUserConsumerAPIGatewayRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: ''
            Effect: 'Allow'
            Principal:
              Service:
                - 'apigateway.amazonaws.com'
            Action:
              - 'sts:AssumeRole'
      Path: '/'
      Policies:
        - PolicyName: LambdaAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action: 'lambda:*'
                Resource: "*"

  DataUserConsumerAPIGateway:
    Type: "AWS::ApiGateway::RestApi"
    Properties:
      Description: "API use to deliver data on demand for my third users"
      Name: !Ref DataUserConsumerAPIName

  DataUserConsumerAPIDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn: 
      - DataUserConsumerAPIMethod1SQLEndpoint
    Properties:
      Description: "Deployment of third data consumer in API"
      RestApiId: !Ref DataUserConsumerAPIGateway

  DataUserConsumerAPIStage:
    Type: "AWS::ApiGateway::Stage"
    Properties:
      DeploymentId: !Ref DataUserConsumerAPIDeployment
      Description: "Stage for third data consumer API"
      RestApiId: !Ref DataUserConsumerAPIGateway
      StageName: 'third_data_consumer_api_stage'

  ####
  # Create all resources and endpoints
  ####

  ## SQL endpoint #1

  LambdaAuthAWS1SQLEndpoint:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: "LambdaAuthAWS"
      Description: "Authorize the request based in permissions of access control tower for #1 sql endpoint."
      Runtime: "python3.9"
      Role: !GetAtt AuthLambdaRole.Arn
      Handler: auth_all_orders_by_range.lambda_handler
      Timeout: 900
      MemorySize: 2000
      Layers:
        - "arn:aws:lambda:us-east-1:770693421928:layer:Klayers-p39-pandas:12"
      Code:
        S3Bucket: "script-poc-case-1"
        S3Key: "custom_auth_lambda/auth_all_orders_by_range.zip"

  LambdaAuthorizerAPI1SQLEndpoint:
    Type: 'AWS::ApiGateway::Authorizer'
    Properties:
      Name: "Auth lambda for #1 SQL endpoint"
      RestApiId: !Ref DataUserConsumerAPIGateway
      Type: "TOKEN"
      IdentitySource: "method.request.header.Authorization"
      AuthorizerUri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2023-03-27/functions/${LambdaAuthAWS1SQLEndpoint.Arn}/invocations'

  Lambda1SQLEndpoint:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: "N1SQLEndpoint"
      Description: "Code of #1 sql endpoint."
      Runtime: "python3.9"
      Role: !GetAtt AuthLambdaRole.Arn
      Handler: auth_all_orders_by_range.lambda_handler
      Timeout: 900
      MemorySize: 2000
      Layers:
        - "arn:aws:lambda:us-east-1:770693421928:layer:Klayers-p39-pandas:12"
      Code:
        S3Bucket: "script-poc-case-1"
        S3Key: "sql_endpoint/all_orders_by_range.zip"

  DataUserConsumerAPIResource1SQLEndpoint:
    Type: AWS::ApiGateway::Resource
    Properties:
      ParentId: !GetAtt DataUserConsumerAPIGateway.RootResourceId
      PathPart: '/get/all_orders_by_range'
      RestApiId: !Ref DataUserConsumerAPIGateway

  DataUserConsumerAPIMethod1SQLEndpoint:
    Type: AWS::ApiGateway::Method
    Properties:
      ApiKeyRequired: false
      AuthorizationType: "CUSTOM"
      AuthorizerId: !Ref LambdaAuthorizerAPI1SQLEndpoint
      HttpMethod: POST
      Integration:
        ConnectionType: INTERNET
        Credentials: !GetAtt DataUserConsumerAPIGatewayRole.Arn
        IntegrationHttpMethod: POST
        PassthroughBehavior: WHEN_NO_MATCH
        TimeoutInMillis: 29000
        Type: AWS_PROXY
        Uri: !Sub 'arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${Lambda1SQLEndpoint.Arn}/invocations'
      OperationName: '/get/all_orders_by_range'
      ResourceId: !Ref DataUserConsumerAPIResource1SQLEndpoint
      RestApiId: !Ref DataUserConsumerAPIGateway





Outputs:
  DatalakeS3NameID:
    Description: "Get name of data lake in S3 in infraestructure."
    Value: !GetAtt DatalakeS3.DomainName
  DatalakeS3URL:
    Description: "URL of website of bucket."
    Value: !GetAtt DatalakeS3.WebsiteURL
  MovingJobID:
    Description: "Logical ID of AWS Glue Job"
    Value: !Ref S3ToS3GlueJob
  DBID:
    Description: "Logical ID of AWS Glue Database"
    Value: !Ref POCCase1Database
  DBS3ID:
    Description: "S3 Path for stored querie from AWS Athena"
    Value: !Join
      - "/"
      - - "s3:/"
        - !Ref ResultedQueryStoreS3
  WorkspaceInAthena:
    Description: "Workspace to save queries inside Athena"
    Value: !Ref AthenaWorkSpace
  CrawlerTablesID:
    Description: "Crawler to generate all tables in destiny location S3"
    Value: !Ref ParserMetadataTableGlueCrawler
